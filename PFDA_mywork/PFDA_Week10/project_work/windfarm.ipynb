{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windfarm Notebook\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The weather data that we are analysing was downloaded from the Met Eireann website. We have downloaded data from the four corners of the country to see if there is a variation in wind speed based on location. We will analyse the data and see if the wind speed for Ireland is changing over time. Is Ireland getting windier, less windier?\n",
    "\n",
    "\n",
    "<div><img src=\"https://d3hnfqimznafg0.cloudfront.net/image-handler/ts/20180403085507/ri/850/src/images/Article_Images/ImageForArticle_703(1).jpg\" alt=\"Domain Names\", width=640, height=360\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Description of Project\n",
    "\n",
    "***\n",
    "\n",
    "### **Tasks** \n",
    "\n",
    "1.  You may look for your own source of historic weather information, and/or\n",
    "    use the Met Eireann one (Historical Data - Met Ã‰ireann - The Irish\n",
    "    Meteorological Service). Click on the download button to get a zip file that\n",
    "    contains a CSV file.\n",
    "1.  You may need to clean and normalize the data before doing analysis\n",
    "\n",
    "**Questions you can ask:**\n",
    "\n",
    "1.  How much wind power is there at a particular location? This is quite open ended, is this just the mean wind speed for\n",
    "    an hour/day/month/year, or should you take into account that there are wind ranges that the windfarms can operate in. (min\n",
    "    max speeds)\n",
    "\n",
    "1.  Some analysis of what power when would be useful (time of day/year)\n",
    "\n",
    "1.  Are the wind speeds likely to be the same in 10 years in the future? ie is there a trend in recorded wind speeds over the last\n",
    "    few decades.\n",
    "\n",
    "1.  Is there any other weather metric worth analyzing (eg rain, temp)\n",
    "\n",
    "1.  What will the power output of the windfarms in Ireland be like next week, according to the weather forecasts? (ok that is a\n",
    "    tricky one,because you would need to get, or make up, information about the size and locations of the wind farms in Ireland, \n",
    "    or find/makeup the windspeed to power output equation.\n",
    "\n",
    "1.  Anything else you can think of?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Libraries\n",
    "\n",
    "***\n",
    "\n",
    "We use [pandas](https://pandas.pydata.org/) for the DataFrame data structure. It allows us to investigate CSV files, amongst other \n",
    "features. \n",
    "Pandas is a software library written for the Python programming language, which is used for data manipulation and analysis.\n",
    "\n",
    "We use [NumPy](https://numpy.org/), which is a library for the Python programming language, which allows us to work with large \n",
    "multi-dimensional arrays and matrices. It also supplies a large collection of high-level mathematical functions to operate on these \n",
    "arrays. \n",
    "[NumPy Wikipedia](https://en.wikipedia.org/wiki/NumPy)\n",
    "\n",
    "We use [matplotlib](https://matplotlib.org/), which is a plotting library for the Python programming language, and is usually used in \n",
    "conjunction with its numerical mathematics extension NumPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from python.createdb import CreateDB as createdb\n",
    "from python.createtable import CreateTable as createtable\n",
    "from python.stations import Stations as stations\n",
    "from python.import_data import Import_Data as import_data\n",
    "from python.writedb import WriteDB as write\n",
    "from python.testdb import TestDB as testdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the weather information for a number of weather stations.\n",
    "\n",
    "Below, we will look at importing the weather data from a number of different locations around the country. We will created python classes to import the datasets into the `data folder` in this repository, and also to import the data to an SQL database called `weather`. We will create tables in the database with the location name of each station that we select for downloading the data from. For example `shannon_airport`, `dublin_airport` etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine created\n",
      "Engine created\n",
      "Engine created\n",
      "Engine created\n",
      "Engine created\n",
      "Engine created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of weather stations and the number of rows to skip in the data file\n",
    "weather_stations = [\n",
    "     [{\"athenry\" :1875}, 17],\n",
    "     [{\"cork_airport\" : 3904}, 23],\n",
    "     [{\"shannon_airport\" : 518}, 23],\n",
    "     [{\"dublin_airport\" : 532}, 23],\n",
    "     [{\"mullingar\": 875}, 17],\n",
    "     [{\"gurteen\" : 1475}, 17]\n",
    "]\n",
    "\n",
    "# Create the database to store the downloaded data\n",
    "'''\n",
    "db = createdb()\n",
    "\n",
    "#Create an instance of the CreateTable class to create the tables in the database\n",
    "tables = createtable()\n",
    "\n",
    "# Create the tables in the database\n",
    "for i in weather_stations:\n",
    "    for name, id in i[0].items():\n",
    "       skiprows = i[1]\n",
    "       tables.create_table(name, skiprows)\n",
    "\n",
    "# Create an instatnce of the import data class to import the data into the data folder\n",
    "# Folder has being created so commenting out to stop it being rerun again and again\n",
    "'''\n",
    "\n",
    "data = import_data()\n",
    "\n",
    "#Import the data from the weather stations\n",
    "for i in weather_stations:\n",
    "    for name, id in i[0].items():\n",
    "        skiprows = i[1]\n",
    "        data.import_data(name, id, skiprows)\n",
    "\n",
    "\n",
    "#Create an instance of the write class to write the data to a database \n",
    "#As above database has being created so commenting out to stop it being rerun again and again\n",
    "#(Takes 4 minutes to load data to sql database)\n",
    "\n",
    "write = write()\n",
    "\n",
    "# Write the data to the database using the station name as the table name\n",
    "for i in weather_stations:\n",
    "    for name, id in i[0].items():\n",
    "        skiprows = i[1]\n",
    "        write.write_db(name, id , skiprows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('01-jan-1962 01:00', 8, None, 0, -1.1, 0, -1.3, -1.6, 5.3, 94.0, 1016.0, 1, 14, 1, 340, 2, 0, None, 30000.0, 999.0, 2.0)\n",
      "('01-jan-1962 02:00', 8, None, 0, -1.1, 0, -1.3, -1.6, 5.3, 94.0, 1016.5, 1, 10, 1, 340, 3, 1, None, 30000.0, 20.0, 7.0)\n",
      "('01-jan-1962 03:00', 8, None, 0, -1.0, 0, -1.2, -1.6, 5.3, 94.0, 1016.7, 1, 12, 1, 320, 1, 1, None, 30000.0, 999.0, 3.0)\n",
      "('01-jan-1962 04:00', 8, None, 0, -1.6, 0, -1.8, -2.2, 5.1, 94.0, 1017.2, 1, 8, 1, 330, 1, 0, None, 30000.0, 999.0, 1.0)\n",
      "('01-jan-1962 05:00', 8, None, 0, -2.1, 0, -2.3, -3.3, 4.8, 93.0, 1018.0, 1, 11, 1, 320, 1, 0, None, 30000.0, 999.0, 0.0)\n",
      "('01-jan-1962 06:00', 8, None, 0, -2.1, 0, -2.3, -3.3, 4.9, 93.0, 1018.1, 1, 11, 1, 330, 2, 1, None, 30000.0, 999.0, 0.0)\n",
      "('01-jan-1962 07:00', 8, None, 0, -2.2, 0, -2.4, -3.3, 4.8, 93.0, 1018.8, 1, 11, 1, 340, 2, 0, None, 30000.0, 999.0, 0.0)\n",
      "('01-jan-1962 08:00', 8, None, 0, -1.6, 0, -1.9, -2.7, 4.9, 92.0, 1019.0, 1, 14, 1, 340, 2, 0, None, 30000.0, 999.0, 0.0)\n",
      "('01-jan-1962 09:00', 8, None, 0, -1.1, 0, -1.6, -2.7, 5.0, 89.0, 1019.7, 1, 12, 1, 340, 3, 0, None, 30000.0, 999.0, 1.0)\n",
      "('01-jan-1962 10:00', 8, None, 0, -1.5, 0, -1.8, -2.7, 5.0, 92.0, 1020.5, 1, 7, 1, 340, 2, 0, None, 40000.0, 999.0, 1.0)\n",
      "('01-jan-1962 11:00', 8, None, 0, -0.6, 0, -0.9, -1.6, 5.4, 92.0, 1021.0, 1, 11, 1, 330, 2, 0, None, 40000.0, 999.0, 1.0)\n",
      "('01-jan-1962 12:00', 8, None, 0, 0.6, 0, -0.2, -2.2, 5.3, 83.0, 1020.4, 1, 8, 1, 340, 2, 0, None, 40000.0, 999.0, 1.0)\n",
      "('01-jan-1962 13:00', 8, None, 0, 1.6, 0, 0.7, -1.1, 5.8, 83.0, 1020.0, 1, 9, 1, 340, 2, 0, None, 40000.0, 999.0, 1.0)\n",
      "('01-jan-1962 14:00', 8, None, 0, 2.3, 0, 1.5, 0.0, 6.2, 85.0, 1020.2, 1, 10, 1, 350, 2, 0, None, 40000.0, 999.0, 1.0)\n",
      "('01-jan-1962 15:00', 8, None, 0, 1.8, 0, 0.3, -2.7, 5.1, 73.0, 1020.2, 1, 9, 1, 350, 2, 0, None, 40000.0, 999.0, 1.0)\n",
      "('01-jan-1962 16:00', 8, None, 0, 1.6, 0, 0.7, -0.5, 5.8, 85.0, 1020.4, 1, 10, 1, 340, 2, 0, None, 40000.0, 999.0, 1.0)\n",
      "('01-jan-1962 17:00', 8, None, 0, 0.2, 0, -0.1, -1.1, 5.8, 93.0, 1020.9, 1, 10, 1, 340, 2, 0, None, 40000.0, 999.0, 1.0)\n",
      "('01-jan-1962 18:00', 8, None, 0, -0.5, 0, -0.9, -1.6, 5.4, 92.0, 1021.7, 1, 6, 1, 350, 2, 0, None, 30000.0, 999.0, 1.0)\n",
      "('01-jan-1962 19:00', 8, None, 0, -1.5, 0, -1.6, -2.2, 5.3, 96.0, 1022.1, 1, 6, 1, 340, 1, 0, None, 24000.0, 999.0, 0.0)\n",
      "('01-jan-1962 20:00', 8, None, 0, -1.6, 0, -1.7, -2.2, 5.2, 96.0, 1022.8, 1, 6, 1, 330, 2, 0, None, 24000.0, 999.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "#Test the database by querying the data\n",
    "test = testdb()\n",
    "\n",
    "#Test the database by querying the data. Print the first 20 rows of the table\n",
    "test.test_db('cork_airport')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets\n",
    "\n",
    "***\n",
    "\n",
    "Since it would be useful to analyse windspeed from the four corners of the country I have downloaded multiple datasets from the Met Eireann website into the `data` folder of this repository above. The datasets were not identical, in so far as they contain a different number of columns depending upon the location they were taken from. Some datasets contained 17 rows metadata, while others contained 23 rows metadata. Some stations have 15 columns data, while other stations have 21 columns data. Therefore the first 17 rows of some of the datasets, and the first 23 rows of other datasets contained `metadata`, and it was important to skip these rows when importing the dataset.  For clarity, I have demonstrated the steps taken to clean the dataset for the `dublin_airport_532.csv` file in the initial part of this notebook.  The `skiprows=23` argument was passed to the `pd.read_csv()` function to skip the metadata contained in the first number of rows. I have used the metadata in the first 23 rows to rename the columns of the dataset. This makes the datset clearer and easier to read. The `skipinitialspace=True` argument was used while importing the dataset, and the reasoning for this is explained below, when we are looking at the missing values in the dataset.\n",
    "\n",
    "We then went on to drop the `indicator` columns in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
