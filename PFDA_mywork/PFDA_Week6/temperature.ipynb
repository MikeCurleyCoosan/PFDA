{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with weather data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                date  ind rain  ind.1  temp  ind.2  wetb  dewpt  vappr  rhum  \\\n",
      "0  10-apr-1996 14:00    0  0.0      0  11.5      0   8.1    3.9    0.0     0   \n",
      "1  31-jul-1996 08:00    0  0.0      0  11.5      0  11.1   10.7    0.0     0   \n",
      "2  31-jul-1996 09:00    0  0.0      0  11.6      0  10.7    9.8    0.0     0   \n",
      "3  31-jul-1996 10:00    0  0.0      0  12.9      0  11.3    9.8    0.0     0   \n",
      "4  31-jul-1996 11:00    0  0.0      0  14.5      0  10.8    7.0    0.0     0   \n",
      "\n",
      "   ... ind.3  wdsp ind.4  wddir  ww   w  sun    vis clht clamt  \n",
      "0  ...     0     0     0      0  25  81  0.0  35000   32     5  \n",
      "1  ...     0     0     0      0  25  82  0.0  40000   45     5  \n",
      "2  ...     0     0     0      0  80  81  0.0   8000   32     7  \n",
      "3  ...     0     0     0      0  25  82  0.0  28000   35     6  \n",
      "4  ...     0     0     0      0   2  11  0.0  40000   40     6  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset\n",
    "\n",
    "df = pd.read_csv('https://cli.fusio.net/cli/climate_data/webdata/hly4935.csv', skiprows=23, low_memory=False)\n",
    "#skiprows=23 is used to skip the first 23 rows of the dataset\n",
    "#low_memory=False is used to suppress the warning message due to mixed data types in the dataset columns\n",
    "\n",
    "#Display the first 5 rows of the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246930, 21)\n"
     ]
    }
   ],
   "source": [
    "#Analyze the dataset\n",
    "#Check the number of rows and columns in the dataset\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date      object\n",
      "ind        int64\n",
      "rain      object\n",
      "ind.1      int64\n",
      "temp     float64\n",
      "ind.2      int64\n",
      "wetb     float64\n",
      "dewpt    float64\n",
      "vappr    float64\n",
      "rhum       int64\n",
      "msl       object\n",
      "ind.3      int64\n",
      "wdsp      object\n",
      "ind.4      int64\n",
      "wddir     object\n",
      "ww        object\n",
      "w         object\n",
      "sun      float64\n",
      "vis       object\n",
      "clht      object\n",
      "clamt     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Check the data types of the columns in the dataset\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date     0\n",
      "ind      0\n",
      "rain     0\n",
      "ind.1    0\n",
      "temp     0\n",
      "ind.2    0\n",
      "wetb     0\n",
      "dewpt    0\n",
      "vappr    0\n",
      "rhum     0\n",
      "msl      0\n",
      "ind.3    0\n",
      "wdsp     0\n",
      "ind.4    0\n",
      "wddir    0\n",
      "ww       0\n",
      "w        0\n",
      "sun      0\n",
      "vis      0\n",
      "clht     0\n",
      "clamt    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date     datetime64[ns]\n",
      "ind               int64\n",
      "rain             object\n",
      "ind.1             int64\n",
      "temp            float64\n",
      "ind.2             int64\n",
      "wetb            float64\n",
      "dewpt           float64\n",
      "vappr           float64\n",
      "rhum              int64\n",
      "msl              object\n",
      "ind.3             int64\n",
      "wdsp             object\n",
      "ind.4             int64\n",
      "wddir            object\n",
      "ww               object\n",
      "w                object\n",
      "sun             float64\n",
      "vis              object\n",
      "clht             object\n",
      "clamt            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the dataset\n",
    "# Convert the date column to a datetime data \n",
    "df['date'] = pd.to_datetime(df['date'], format='%d-%b-%Y %H:%M') #format='%d-%b-%Y %H:%M' is used to specify the format of the date column\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0' '0.1' ' ' '1.0' '3.1' '0.7' '0.3' '0.6' '1.5' '3.3' '0.2' '0.4'\n",
      " '2.3' '1.2' '0.5' '1.9' '0.8' '0.9' '1.1' '4.8' '1.3' '13.4' '1.7' '3.4'\n",
      " '1.6' '2.8' '1.4' '2.7' '4.0' '2.1' '4.7' '2.0' '2.2' '3.7' '2.4' '4.1'\n",
      " '3.2' '2.6' '1.8' '4.4' '6.5' '6.1' '3.5' '3.6' '2.9' '2.5' '5.2' '4.2'\n",
      " '4.6' '4.3' '3.9' '5.5' '7.8' '5.7' '3.8' '3.0' '5.4' '7.3' '7.5' '8.0'\n",
      " '4.9' '6.6' '6.7' '5.1' '8.5' '9.9' '5.0' '7.0' '8.2' '6.2' '12.9' '13.2'\n",
      " '8.9' '6.3' '6.0' '6.9' '8.1' '14.2' '5.9' '11.4' '4.5' '11.6' '5.6'\n",
      " '9.1' '8.6' '5.8' '8.4' '16.0' '6.4' '16.5' '7.6' '6.8' '5.3' '7.4' '9.0'\n",
      " '11.7' '7.2' '8.7' '9.4' '10.9' '12.4' '18.7' '13.6' '7.7' '15.2' '16.9'\n",
      " '11.1' '8.3' '8.8' '7.9' '9.2' '13.8' '9.5' '12.7' '11.9' '10.0']\n"
     ]
    }
   ],
   "source": [
    "#Now deal with the mixed data types in the dataset\n",
    "#Check the unique values in the 'rain' column\n",
    "print(df['rain'].unique())\n",
    "\n",
    "#Okay, we can see that the 'rain' column contains the string '---' which is causing the column to be of object data type\n",
    "#Replace the '---' values with 0.0\n",
    "\n",
    "df['rain'] = df['rain'].replace(' ', 0.0)\n",
    "\n",
    "#Convert the 'rain' column to float data type\n",
    "df['rain'] = df['rain'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.1 11.1 10.7 11.3 10.8 10.9 10.4 10.6 11.  10.2 10.1  8.8  9.   8.5\n",
      "  8.6  9.3  9.1  9.2  9.5  9.7 12.  11.6 11.7 11.8 11.2 10.5  9.6  9.4\n",
      " 10.  11.4 11.5 12.1 11.9 12.6 12.8 12.4 12.7 13.  13.2 13.7 13.4 13.6\n",
      " 13.8  9.9 12.9 13.1 13.5 13.9  0.  13.3 12.2 10.3  8.9  8.7  9.8 12.5\n",
      " 14.1 14.2 12.3 14.  15.5 14.6 15.3 15.  15.1 14.9 14.7 15.4 15.6 15.7\n",
      " 14.4 14.5 14.3 14.8 15.2 15.9 16.  16.1 15.8 16.3 16.6 17.  17.6 17.7\n",
      " 17.4 16.8 16.5 16.4  8.4  7.8  7.7  8.2  7.9  8.   7.4  7.5 17.3 17.2\n",
      " 16.9 17.5 17.9 16.7  7.6  8.3  7.2  7.   7.1  6.7  6.1  6.   6.4  6.8\n",
      "  5.9  6.2  5.5  5.7  7.3  6.9  6.3  5.8  6.5  6.6  5.3  5.4  5.6  5.2\n",
      "  5.1  5.   4.9  4.6  4.4  4.5  4.3  4.1  4.   4.8  4.7  3.8  3.9  3.7\n",
      "  4.2  3.6  3.4  3.5  3.2  2.6  1.4  1.2  1.1  1.7  1.3  2.   2.8  2.9\n",
      "  3.1  2.2  2.5  2.4  2.3  1.8  0.2  0.5  0.3  0.6  0.7  0.1 -0.4  1.\n",
      "  0.8  0.4 -0.1 -0.3 -0.5 -1.  -0.9  3.3  2.7  1.5  3.   1.9  2.1 -0.8\n",
      " -0.7 -0.2  0.9 -1.1 -1.5 -1.7 -1.3 -1.8  1.6 -0.6 -2.  -1.2 -1.6 -1.4\n",
      " -2.1 -1.9 -2.2 -2.3 -2.4 -3.1 -3.3 -4.1 -3.4 -3.2 -2.9 -2.5 -3.  -3.6\n",
      " -3.9 -3.8 -3.5 16.2 17.1 18.7 19.4 20.  19.6 19.5 19.7 18.2 19.3 19.1\n",
      " 18.9 19.  18.  18.3 17.8 18.1 19.2 18.6 18.5 -2.6 -2.7 20.2 18.4 -4.8\n",
      " -4.9 -2.8 -4.  -5.8 -6.2 -6.7 -5.5 -4.7 -4.4 -3.7 -4.2 -5.1 -5.4 -5.\n",
      " -4.3 -4.6 18.8 20.1 20.6 21.6 21.8 21.5 21.7 21.3 20.8 19.8 19.9 20.7\n",
      " 20.5 20.3 20.4 -5.3 -5.9 -5.2 -5.6 -4.5 -5.7 -6.  -6.9 -6.4 -6.6 -6.8\n",
      " 20.9 21.  21.2 21.1 -7.1 -7.3 -7.  -6.3 23.8 22.8]\n"
     ]
    }
   ],
   "source": [
    "#Rain column is now done, let's check the unique values in the 'wetb' column\n",
    "print(df['wetb'].unique())\n",
    "\n",
    "#We can see that the 'wetb' column contains integer values and float values\n",
    "#Convert the 'wetb' column to float data type\n",
    "df['wetb'] = df['wetb'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.9  10.7   9.8   7.    7.3   6.7   8.6   7.5   9.6   8.5   9.4   9.5\n",
      "   7.9   8.3   7.1   7.2   8.2   8.1   8.8   9.2   8.9   9.1   9.3  10.\n",
      "  10.8  10.6  10.4  10.3   9.9  10.1   8.7  10.2  10.9  11.2  11.7   9.7\n",
      "  11.1  11.3  11.4  11.5  11.    9.   11.6  10.5  11.8   0.   12.   12.5\n",
      "  12.8  12.9  13.1  13.2  13.   12.1   7.8   8.    6.8   6.9   7.4   7.7\n",
      "   7.6  12.4  13.4  13.8  14.   12.2  11.9  13.5  12.3  12.6  12.7  13.3\n",
      "  14.1  14.2  14.6  14.7  14.8  15.5  15.1  14.3  14.4  13.9  13.6  13.7\n",
      "  15.3  15.9  15.6  15.4  15.2  15.   15.8  16.3  16.6  16.9  17.2  17.1\n",
      "  16.7  14.9  14.5   8.4   6.4   6.5   6.3   4.7   5.6   5.4  16.   16.5\n",
      "  16.4  16.8  17.   15.7  16.1   5.7   6.    5.5   4.5   5.1   4.8   6.1\n",
      "   6.6   6.2   5.8   5.9   5.2   4.6   4.4   4.9   4.2   4.3   5.3   4.1\n",
      "   5.    4.    3.8   3.7   3.6   2.8   3.4   0.7   2.9   3.    3.3   3.2\n",
      "   3.5   3.1   0.6   1.6   1.7   2.5   2.4   2.3   1.9   1.1   1.3   0.5\n",
      "   0.2   0.3   1.2   0.9   1.5   2.6   2.    1.4   2.7   1.8  -0.3  -0.2\n",
      "   0.1  -0.4  -0.8  -0.1  -0.6  -1.2  -1.7  -1.9  -1.5  -0.9  -1.8  -0.7\n",
      "   0.4   0.8   1.    2.1   2.2  -1.1  -1.   -2.4  -2.7  -2.2  -2.   -2.6\n",
      "  -2.3  -3.9  -1.3  -2.5  -3.4  -3.5  -2.9  -2.8  -3.1  -0.5  -2.1  -3.\n",
      "  -1.6  -1.4  -3.3  -4.   -3.6  -4.1  -3.7  -3.8  -3.2  -4.8  -5.3  -4.5\n",
      "  -4.3  -4.6  -4.2  -4.4  -4.7  16.2  17.3  17.8  18.6  18.3  18.   18.2\n",
      "  17.5  17.7  18.7  17.4  18.5  18.1  17.9  -7.1  -5.6  -5.5  -9.5  -5.4\n",
      "  -5.9  -5.8  -6.6  -5.   -6.5  -5.1  -6.1  -6.8  -7.   -7.6  -6.2  -5.7\n",
      "  -5.2  -6.7  -6.3  -6.   -6.9  -4.9  -7.8  -7.2  -7.4  -7.5  17.6  19.3\n",
      "  19.2  19.5  19.7  19.6  18.9  18.8  18.4  -6.4  -8.6  -8.4  -7.7  -8.3\n",
      "  -8.   -8.5  -7.9  -9.3 -10.6 -11.4  -7.3  -8.8  -9.4  -8.1  -8.2  19.\n",
      "  19.4  -9.7  -9.1  -8.9  -9.   -9.2  20.2  21.5  20.6  22.5  21.8  21.1\n",
      "  19.9  19.1  19.8]\n"
     ]
    }
   ],
   "source": [
    "#Check the unique values in the 'dewpt' column\n",
    "print(df['dewpt'].unique())\n",
    "\n",
    "#We can see that the 'dewpt' column contains integer values and float values\n",
    "#Convert the 'dewpt' column to float data type\n",
    "df['dewpt'] = df['dewpt'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  10.6 10.  10.9 10.1 10.8 11.3 11.7 11.4 11.5 11.8 12.3 11.9 12.1\n",
      " 13.  12.8 12.6 12.5 12.2 12.9 12.4 11.2 11.1 13.1 13.3 13.7 12.  13.2\n",
      " 13.4 13.5 13.8 12.7 10.4  6.1 14.  14.4 14.5 14.8 14.9 15.1 15.2 15.\n",
      " 14.1 11.6  9.9 10.2 10.3 10.5 10.7 15.4 15.8 16.  14.2 13.9 13.6 15.5\n",
      " 14.3 14.7 15.3 14.6 16.1 16.2 16.6 16.7 16.8 17.6 17.1 16.3 16.4 15.9\n",
      " 15.6 15.7 17.4 18.  17.7 17.3 17.5 17.2 17.  17.9 18.5 18.9 19.3 19.6\n",
      " 19.5 19.2 19.  18.1 16.9 16.5 11.   9.6  8.5  9.1  9.   9.8 18.2 17.8\n",
      " 18.8 18.7 19.1 19.4 18.3 18.6  9.2  9.3  8.4  8.8  8.6  9.4  9.7  9.5\n",
      "  8.3  8.7  8.9  8.2  8.1  8.   7.9  7.5  7.8  6.4  7.6  7.4  7.7  6.8\n",
      "  6.9  7.3  7.2  7.   6.6  6.7  6.3  6.2  6.5  6.   5.9  5.8  7.1  5.6\n",
      "  5.4  5.3  5.5  5.7  5.1  5.   5.2  4.6  4.8  4.7  4.9  4.5  4.4  4.3\n",
      " 18.4 19.7 20.4 21.4 21.  20.7 20.9 19.9 20.3 21.5 19.8 20.  21.3 20.8\n",
      " 20.6 20.5 20.2  3.6  4.   4.1  3.   3.9  3.7  4.2  3.8  3.5  3.4 20.1\n",
      " 22.4 22.3 22.6 23.  22.9 22.8 21.8 21.7 21.2 21.6  3.2  3.3  2.7  2.6\n",
      "  3.1 21.1 22.  21.9 22.7 22.5 22.2  2.9 23.6 25.5 24.2 27.2 26.1 25.1\n",
      " 23.2 22.1]\n"
     ]
    }
   ],
   "source": [
    "#Check the unique values in the 'vappr' column\n",
    "print(df['vappr'].unique())\n",
    "\n",
    "#We can see that the 'vappr' column contains integer values and float values\n",
    "#Convert the 'vappr' column to float data type\n",
    "df['vappr'] = df['vappr'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0  92  82  87  81  88  85  89  83  78  79  74  70  73  80  76  95  96\n",
      "  97  91  99 100  94  84  71  69  68  72  77  93  98  67  61  58  60  65\n",
      "  90  59  55  54  47  51  52  56  86  66  62  64  63  75  46  57  48  53\n",
      "  50  49  43  45  44  42  36  38  41  40  34  33  39  37  35  31  30  32\n",
      "  29  27  26  25  28  22]\n"
     ]
    }
   ],
   "source": [
    "#Check the unique values in the 'rhum' column\n",
    "print(df['rhum'].unique())\n",
    "\n",
    "#We can see that the 'rhum' column contains integer values and a zero value\n",
    "#We should leave the zero value as it is because it is a valid value\n",
    "#We should convert the 'rhum' column to an integer data type\n",
    "df['rhum'] = df['rhum'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1016.7' '1011.4' '1011.2' '1011.0' '1010.9' '1011.3' '1011.6' '1011.8'\n",
      " '1011.1' '1011.5' '1012.2' '1012.6' '1013.1' '1013.5' '1013.8' '1014.2'\n",
      " '1015.0' '1015.5' '1015.6' '1016.2' '1017.0' '1017.6' '1018.5' '1019.2'\n",
      " '1019.6' '1020.3' '1020.7' '1021.0' '1020.9' '1021.4' '1021.6' '1021.9'\n",
      " '1022.6' '1023.2' '1023.8' '1024.3' '1024.6' '1024.8' '1025.4' '1025.7'\n",
      " '1026.2' '1026.5' '1026.7' '1027.0' '1027.2' '1027.6' '1028.2' '1028.3'\n",
      " '1028.5' '1028.6' '1028.7' '1028.8' '1028.9' '1028.4' '1027.9' '1026.9'\n",
      " '1026.8' '1026.6' '1026.3' '1026.0' '1025.3' '1022.8' '1022.3' '1022.1'\n",
      " '1021.5' '1020.4' '1018.3' '1017.7' '1016.4' '1014.1' '1013.2' '1012.1'\n",
      " '1010.7' '1010.2' '1009.9' ' ' '1009.3' '1008.9' '1008.6' '1007.9'\n",
      " '1007.6' '1007.4' '1007.0' '1006.9' '1007.1' '1008.3' '1009.0' '1009.2'\n",
      " '1009.5' '1010.0' '1010.3' '1009.8' '1010.8' '1010.5' '1010.1' '1010.4'\n",
      " '1010.6' '1011.7' '1012.4' '1013.4' '1014.4' '1014.9' '1016.1' '1016.5'\n",
      " '1015.4' '1015.7' '1015.2' '1014.7' '1014.3' '1009.4' '1008.7' '1007.7'\n",
      " '1006.7' '1005.8' '1005.1' '1003.5' '1003.6' '1003.1' '1002.7' '1002.8'\n",
      " '1003.0' '1003.8' '1003.9' '1004.4' '1004.9' '1005.0' '1004.7' '1004.3'\n",
      " '1004.1' '1003.4' '1003.2' '1002.6' '1002.3' '1001.6' '1001.2' '1000.4'\n",
      " '999.4' '998.7' '997.7' '997.1' '996.1' '995.3' '994.4' '993.5' '992.6'\n",
      " '991.5' '992.4' '994.2' '994.3' '994.5' '994.7' '995.0' '995.5' '995.6'\n",
      " '995.4' '995.7' '996.9' '997.5' '997.8' '998.4' '999.6' '1000.6' '1001.1'\n",
      " '1002.1' '1002.9' '1004.5' '1005.6' '1006.2' '1008.0' '1009.6' '1013.6'\n",
      " '1014.5' '1015.1' '1016.0' '1016.3' '1016.6' '1016.8' '1016.9' '1017.1'\n",
      " '1017.3' '1018.0' '1018.2' '1018.6' '1019.4' '1019.5' '1019.7' '1019.8'\n",
      " '1020.0' '1019.9' '1020.8' '1021.1' '1021.2' '1021.3' '1022.0' '1023.0'\n",
      " '1023.4' '1023.1' '1022.9' '1022.5' '1020.1' '1020.2' '1019.3' '1019.0'\n",
      " '1019.1' '1018.8' '1018.9' '1018.1' '1017.8' '1018.4' '1017.9' '1017.5'\n",
      " '1015.3' '1014.6' '1014.0' '1013.0' '1012.0' '1011.9' '1009.7' '1012.7'\n",
      " '1014.8' '1013.9' '1013.3' '1012.9' '1012.5' '1009.1' '1008.8' '1008.4'\n",
      " '1007.2' '1006.3' '1005.3' '1002.0' '1000.7' '999.7' '998.5' '998.2'\n",
      " '998.8' '998.9' '998.6' '999.2' '999.0' '1000.0' '1000.1' '1000.3'\n",
      " '1000.2' '999.8' '999.1' '999.3' '998.3' '998.1' '1000.9' '1001.3'\n",
      " '1001.9' '1002.2' '1003.7' '1004.6' '1005.2' '1005.4' '1006.1' '1007.5'\n",
      " '1013.7' '1015.9' '1020.6' '1021.7' '1021.8' '1023.7' '1024.9' '1025.0'\n",
      " '1025.2' '1025.1' '1025.5' '1025.8' '1025.6' '1025.9' '1024.2' '1024.1'\n",
      " '1023.6' '1022.4' '1022.2' '1022.7' '1023.9' '1024.4' '1026.1' '1026.4'\n",
      " '1027.5' '1027.4' '1027.8' '1029.4' '1030.0' '1030.3' '1030.5' '1030.9'\n",
      " '1030.7' '1030.6' '1030.8' '1031.1' '1031.7' '1031.5' '1031.3' '1031.2'\n",
      " '1029.7' '1029.6' '1029.8' '1029.5' '1029.3' '1029.2' '1027.1' '1028.0'\n",
      " '1029.0' '1029.1' '1027.7' '1027.3' '1024.7' '1024.5' '1024.0' '1023.3'\n",
      " '1030.2' '1031.0' '1031.6' '1032.0' '1032.4' '1032.5' '1032.7' '1032.6'\n",
      " '1033.1' '1033.2' '1033.4' '1033.5' '1033.3' '1033.8' '1034.1' '1034.5'\n",
      " '1034.8' '1034.7' '1034.6' '1035.0' '1034.9' '1035.3' '1035.1' '1034.2'\n",
      " '1033.9' '1033.6' '1033.0' '1032.9' '1031.8' '1030.4' '1028.1' '1020.5'\n",
      " '1012.8' '1012.3' '1015.8' '1017.2' '1007.3' '1006.4' '1006.5' '1006.6'\n",
      " '1005.9' '1005.7' '1001.0' '997.2' '996.2' '1001.4' '1002.5' '1003.3'\n",
      " '1006.8' '1004.8' '1004.2' '997.6' '996.4' '994.1' '993.8' '993.7'\n",
      " '994.6' '996.0' '996.6' '998.0' '1005.5' '1008.2' '1001.8' '1004.0'\n",
      " '1008.1' '1006.0' '1008.5' '1023.5' '1018.7' '1000.5' '999.5' '997.4'\n",
      " '996.8' '996.3' '993.0' '992.2' '990.9' '990.3' '989.6' '988.9' '988.2'\n",
      " '987.7' '986.2' '985.3' '985.1' '984.8' '984.4' '984.0' '983.8' '983.9'\n",
      " '984.6' '985.7' '986.0' '985.9' '986.5' '987.4' '988.8' '989.1' '989.5'\n",
      " '989.7' '989.9' '990.7' '991.3' '992.8' '993.3' '993.6' '993.9' '995.1'\n",
      " '995.8' '997.0' '994.9' '992.7' '992.5' '992.3' '992.9' '993.1' '994.0'\n",
      " '991.9' '991.1' '990.2' '988.3' '986.6' '985.6' '984.2' '987.0' '989.0'\n",
      " '990.6' '992.1' '1000.8' '997.9' '995.2' '993.2' '992.0' '990.5' '990.4'\n",
      " '990.1' '989.3' '989.2' '1017.4' '1007.8' '1001.5' '1002.4' '996.7'\n",
      " '994.8' '999.9' '983.7' '981.3' '979.7' '978.1' '977.0' '975.9' '975.2'\n",
      " '974.8' '974.2' '973.4' '972.8' '972.7' '973.8' '981.0' '988.6' '988.0'\n",
      " '986.8' '985.8' '983.6' '981.8' '981.2' '979.9' '977.1' '978.9' '981.1'\n",
      " '982.0' '982.5' '988.5' '991.0' '996.5' '988.4' '990.8' '991.2' '991.7'\n",
      " '995.9' '987.9' '980.5' '980.0' '980.1' '980.9' '981.6' '982.3' '983.3'\n",
      " '984.1' '986.3' '986.9' '991.8' '997.3' '1001.7' '987.1' '986.4' '987.5'\n",
      " '988.1' '989.8' '1031.9' '1032.2' '1034.4' '1034.0' '1033.7' '1032.8'\n",
      " '1032.1' '1029.9' '1030.1' '1031.4' '1034.3' '1035.2' '1035.6' '1036.0'\n",
      " '1036.5' '1037.3' '1037.9' '1038.4' '1039.3' '1039.8' '1039.7' '1040.1'\n",
      " '1040.5' '1041.2' '1041.9' '1042.8' '1043.0' '1043.4' '1043.7' '1044.0'\n",
      " '1044.1' '1044.4' '1044.5' '1044.7' '1044.9' '1045.1' '1044.8' '1044.3'\n",
      " '1043.9' '1043.8' '1043.6' '1044.6' '1045.0' '1043.1' '1042.9' '1042.5'\n",
      " '1042.4' '1042.3' '1041.4' '1041.3' '1041.0' '1041.1' '1040.8' '1040.7'\n",
      " '1040.3' '1040.0' '1039.6' '1039.1' '1038.8' '1038.9' '1039.2' '1039.4'\n",
      " '1039.0' '1038.5' '1037.8' '1037.2' '1037.0' '1037.1' '1036.9' '1036.3'\n",
      " '1035.9' '1035.5' '991.4' '987.2' '989.4' '987.3' '987.8' '984.3' '980.4'\n",
      " '982.1' '983.1' '985.2' '987.6' '982.9' '984.5' '981.4' '975.1' '977.2'\n",
      " '974.9' '974.4' '973.5' '975.7' '976.9' '977.4' '977.7' '976.8' '976.6'\n",
      " '976.4' '975.8' '975.6' '974.7' '972.0' '970.9' '969.9' '969.5' '969.3'\n",
      " '968.9' '968.6' '968.3' '968.8' '970.1' '970.7' '971.6' '972.6' '973.7'\n",
      " '975.4' '977.3' '978.8' '980.6' '983.4' '986.7' '1035.4' '1036.4'\n",
      " '1037.7' '1036.7' '1036.1' '1036.2' '1032.3' '1036.6' '1035.7' '1036.8'\n",
      " '1035.8' '984.9' '984.7' '993.4' '990.0' '982.8' '982.4' '991.6' '985.5'\n",
      " '983.0' '981.9' '982.6' '983.5' '988.7' '986.1' '985.0' '982.2' '981.7'\n",
      " '979.8' '979.4' '979.3' '979.5' '979.6' '980.8' '981.5' '982.7' '985.4'\n",
      " '980.3' '979.0' '978.4' '977.6' '978.7' '978.6' '978.0' '975.0' '976.7'\n",
      " '977.9' '977.8' '978.3' '980.7' '975.5' '972.5' '977.5' '979.2' '976.0'\n",
      " '969.2' '971.5' '972.3' '974.5' '973.3' '973.1' '973.9' '978.2' '969.1'\n",
      " '970.2' '970.0' '971.0' '974.6' '1037.5' '1038.1' '1038.7' '1039.9'\n",
      " '1040.2' '1040.4' '1038.6' '1038.0' '1037.6' '1037.4' '1038.3' '1038.2'\n",
      " '1039.5' '1042.0' '1042.6' '1043.5' '1044.2' '1045.2' '1045.4' '1045.5'\n",
      " '1045.3' '1045.6' '1043.3' '1042.7' '1042.2' '1041.8' '1041.5' '1041.6'\n",
      " '973.0' '972.2' '971.3' '971.1' '971.4' '971.7' '972.4' '973.2' '976.2'\n",
      " '972.1' '967.0' '967.4' '970.4' '972.9' '968.2' '980.2' '978.5' '976.3'\n",
      " '974.3' '973.6' '974.1' '971.2' '974.0' '975.3' '979.1' '983.2' '976.1'\n",
      " '970.8' '976.5' '1040.9' '1045.7' '1046.0' '1045.9' '967.2' '967.3'\n",
      " '1041.7' '1045.8' '1046.3' '1046.7' '1046.2' '1046.6' '1046.5' '1046.1'\n",
      " '1046.4' '1046.9' '1040.6' '968.5' '968.1' '970.5' '969.4' '969.7'\n",
      " '968.7' '967.7' '967.1' '971.9' '969.8' '967.8' '966.1' '965.6' '966.4'\n",
      " '967.6' '971.8' '970.6' '969.0' '966.7' '966.3' '966.2' '964.4' '963.0'\n",
      " '961.2' '959.5' '958.1' '958.9' '962.0' '963.8' '965.3' '968.4' '965.0'\n",
      " '963.5' '961.3' '960.8' '961.4' '964.7' '1043.2' '1042.1' '1046.8'\n",
      " '970.3' '969.6' '965.8' '963.6' '965.2' '966.5' '967.5' '967.9' '961.9'\n",
      " '959.7' '957.6' '956.5' '955.2' '954.1' '953.6' '954.3' '956.2' '959.1'\n",
      " '960.3' '961.5' '962.3' '964.5' '968.0' '966.9' '965.7' '966.0' '963.2'\n",
      " '962.4' '961.1' '960.9' '961.7' '962.6' '964.0' '960.4' '958.2' '958.7'\n",
      " '958.8' '959.3' '959.0' '960.1' '958.5' '958.0' '957.5' '957.9' '959.6'\n",
      " '960.7' '961.0' '961.8' '964.2' '960.5' '955.9' '951.9' '951.1' '952.5'\n",
      " '952.9' '953.3' '955.7' '957.8' '960.2' '965.4' '963.4' '964.8' '965.9'\n",
      " '965.1' '964.3' '962.5' '960.0' '964.9' '962.1' '960.6' '959.2' '959.4'\n",
      " '959.8' '959.9' '962.2' '964.6' '963.7' '956.8' '954.2' '951.8' '949.9'\n",
      " '948.6' '948.2' '948.4' '949.0' '949.5' '950.2' '950.7' '951.7' '954.5'\n",
      " '962.9' '963.9' '961.6' '957.0' '955.8' '963.3' '966.8' '963.1' '1047.5'\n",
      " '1047.8' '1048.2' '1049.0' '1049.6' '1049.9' '1049.7' '1050.0' '1049.5'\n",
      " '1049.3' '1048.8' '1048.6' '1048.5' '1049.4' '1049.2' '1049.1' '1047.2'\n",
      " '962.8' '966.6']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsl\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#We can see that the 'msl' column contains missing values represented by '---'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#Replacing these with a zero value makes no sense because the mean sea level pressure cannot be zero\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#We can replace the missing values with the mean of the column\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#But first, we need to convert the 'msl' column to a float data type\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Convert the 'msl' column to float data type\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsl\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsl\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#Calculate the mean of the 'msl' column\u001b[39;00m\n\u001b[0;32m     12\u001b[0m mean_msl \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsl\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m   6320\u001b[0m     ]\n\u001b[0;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    454\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    455\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    456\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    457\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    184\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' '"
     ]
    }
   ],
   "source": [
    "#Check the unique values in the 'msl' column\n",
    "print(df['msl'].unique())\n",
    "\n",
    "#We can see that the 'msl' column contains missing values represented by '---'\n",
    "#Replacing these with a zero value makes no sense because the mean sea level pressure cannot be zero\n",
    "#We can replace the missing values with the mean of the column\n",
    "#But first, we need to convert the 'msl' column to a float data type\n",
    "#Convert the 'msl' column to float data type\n",
    "df['msl'] = df['msl'].astype(float)\n",
    "\n",
    "#Calculate the mean of the 'msl' column\n",
    "mean_msl = df['msl'].mean()\n",
    "\n",
    "#Replace the zero values with the mean of the column\n",
    "df['msl'] = df['msl'].replace('0.0', mean_msl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '6' '8' '9' '7' '11' '13' '12' '14' '10' ' ' '4' '5' '3' '2' '15'\n",
      " '16' '17' '18' '19' '1' '20' '23' '21' '22' '24' '25' '28' '26' '29' '31'\n",
      " '32' '35' '33' '27' '30' '39' '37' '36' '38' '34' '42' '49' '50' '48'\n",
      " '43' '40']\n"
     ]
    }
   ],
   "source": [
    "#Check the unique values in the 'wdsp' column\n",
    "print(df['wdsp'].unique())\n",
    "\n",
    "#We can see that the 'wdsp' column contains missing values represented by ' '\n",
    "#Replacing these with a zero value makes no sense because the wind speed cannot be zero\n",
    "#We can look at the time of year and the location of the weather station to estimate the wind speed\n",
    "#But for now, we can replace the missing values with the mean of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
